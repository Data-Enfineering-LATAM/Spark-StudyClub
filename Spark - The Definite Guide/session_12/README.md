## Session 12
### Part IV - Production Applications (2/2)

![Banner Session 12](/assets/banner_session_12.png)

### Resumen
En esta sesión, nos enfocamos en los tópicos relevantes respecto a la implementación de aplicaciones en Spark dentro de un cluster de Kubernetes. Kubernetes fue incorporado como Resource Manager en Spark 2.3, aunque fue marcado como GA (Generally Available) y "production-ready" con el Spark 3.1. Iremos conocer la arquitectura de un cluster de Kubernetes, las opciones que nos ofrece Spark y los pasos necesarios para implementar una aplicación en Kubernetes.

Entre los tópicos relevantes de la sesión se encontraban:

* La arquitectura de un cluster de Kubernetes
* ¿Porqué Spark en Kubernetes?
* Implementación de una aplicación mediante *spark-submit*
* Implementación de una aplicación mediante un Spark Operator
* Algunas opciones de monitoreo y depuración que nos ofrece Spark en Kubernetes

Se implementó una aplicación en un cluster de Kubernetes utilizando los archivos de este [repositório en Github](https://github.com/kauvinlucas/spark-kubernetes)

#### Grabación de la sesión



#### Nuestras redes sociales
* [Youtube](https://www.youtube.com/channel/UCqFCoUEvxR23ymmih0GD7mQ?sub_confirmation=1 'Subscríbate al canal')
* [Linkedin](https://www.linkedin.com/company/data-engineering-latam/ 'Síganos en Linkedin')
* [Facebook](https://www.facebook.com/dataengineeringlatam/ 'Síganos en Facebook')
* [Website](https://expy.bio/dataengineeringlatam 'Nuestro website')
